# FastAPI SDK ðŸš€

![FastAPI SDK](https://img.shields.io/badge/FastAPI%20SDK-v1.0.0-brightgreen)

Welcome to the **FastAPI SDK** repository! This project provides a robust and efficient solution for integrating large language model (LLM) APIs. With support for multiple providers like OpenAI, Azure, and others, this SDK is designed for enterprise-level applications. 

## Table of Contents

- [Introduction](#introduction)
- [Features](#features)
- [Installation](#installation)
- [Usage](#usage)
- [Supported Models](#supported-models)
- [API Reference](#api-reference)
- [Deployment](#deployment)
- [Contributing](#contributing)
- [License](#license)
- [Contact](#contact)
- [Releases](#releases)

## Introduction

The FastAPI SDK simplifies the integration of various LLM APIs into your applications. It is lightweight, efficient, and stable, making it ideal for both development and production environments. The clean and simple design enhances usability, allowing developers to focus on building features rather than managing complex integrations.

## Features

- **Multi-provider Support**: Easily switch between different LLM providers.
- **Lightweight**: Minimal overhead for faster performance.
- **Stable**: Built with reliability in mind for enterprise applications.
- **Docker Deployment**: Quick one-click deployment using Docker.
- **User-friendly Interface**: Simple design for easy navigation and usage.

## Installation

To get started with the FastAPI SDK, follow these steps:

1. Clone the repository:
   ```bash
   git clone https://github.com/faisal686/fastapi-sdk.git
   ```
   
2. Navigate to the project directory:
   ```bash
   cd fastapi-sdk
   ```

3. Install the required dependencies:
   ```bash
   pip install -r requirements.txt
   ```

4. Run the application:
   ```bash
   uvicorn main:app --reload
   ```

## Usage

After installing the SDK, you can easily integrate it into your applications. Hereâ€™s a basic example of how to use the SDK:

```python
from fastapi import FastAPI
from fastapi_sdk import LLMClient

app = FastAPI()
client = LLMClient(provider="openai", api_key="your_api_key")

@app.get("/generate")
async def generate_text(prompt: str):
    response = await client.generate(prompt)
    return {"response": response}
```

This example shows how to create a simple FastAPI application that generates text using the OpenAI API.

## Supported Models

The FastAPI SDK supports a variety of models, including:

- **OpenAI GPT-4**
- **Azure OpenAI**
- **Baidu Wenxin Yiyan**
- **iFlytek Spark**
- **Tongyi Qianwen**
- **Zhiyuan GLM**
- **Gemini**
- **DeepSeek**
- **Anthropic Claude**

You can easily switch between these models by changing the provider in your code.

## API Reference

For a complete list of available endpoints and their descriptions, refer to the API documentation. Each endpoint is designed to be intuitive and easy to use.

### Example Endpoints

- **Generate Text**: `/generate`
- **Chat Interface**: `/chat`
- **Model Info**: `/models`

## Deployment

To deploy the FastAPI SDK using Docker, follow these steps:

1. Build the Docker image:
   ```bash
   docker build -t fastapi-sdk .
   ```

2. Run the Docker container:
   ```bash
   docker run -d -p 8000:8000 fastapi-sdk
   ```

Your application will now be accessible at `http://localhost:8000`.

## Contributing

We welcome contributions to the FastAPI SDK! If you want to contribute, please follow these steps:

1. Fork the repository.
2. Create a new branch for your feature or bug fix.
3. Make your changes and commit them.
4. Push your branch to your fork.
5. Open a pull request.

Please ensure that your code adheres to our coding standards and includes appropriate tests.

## License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

## Contact

For questions or feedback, please reach out to the maintainer:

- **Name**: Faisal
- **Email**: faisal@example.com

## Releases

To download the latest version of the FastAPI SDK, visit our [Releases](https://github.com/faisal686/fastapi-sdk/releases) section. Here, you can find the latest updates and download links for the SDK.

For detailed instructions on downloading and executing the latest version, check the releases page. 

## Conclusion

The FastAPI SDK provides a streamlined approach to integrating various LLM APIs. Its focus on simplicity, efficiency, and stability makes it an excellent choice for developers looking to leverage the power of large language models. 

We invite you to explore the SDK and contribute to its development. Thank you for your interest in the FastAPI SDK!